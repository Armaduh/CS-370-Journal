# CS-370-Journal

This project was all about training an intelligent pirate agent to find treasure in a maze using reinforcement learning. I was given some base code that handled the maze structure and environment setup, but most of the RL side was up to me. I had to build the neural network model, set up the training process, and figure out how to make the agent learn through trial and error.

The main challenge was making the agent not just find the treasure once, but learn how to consistently succeed from any starting point. I wrote the Q-learning logic, experience replay, and reward system that actually trains the pirate to make smart choices. It wasn’t easy at first—I had to tweak a bunch of parameters and restart training more times than I’d like to admit—but eventually the agent started winning consistently.

This course tied together a lot of big ideas in AI, from neural networks to reinforcement learning and how those apply in real-world problems. Building the agent made me appreciate how much tuning and experimentation goes into machine learning, even for what seems like a simple task.

More broadly, this reinforced how computer science is about problem-solving with structure and creativity. As a computer scientist, I approach problems by breaking them down—what’s the environment? what are the rules? what feedback do I get? From there, I can start building a solution that learns or adapts over time, just like in this maze project.

Even though this was a maze game, the bigger picture isn’t lost on me. AI systems are trained to make decisions based on rewards—just like this pirate—and in the real world, it’s easy to reward the wrong thing without realizing it. That’s where ethics come in.

As someone building these systems, I know I have a responsibility to think about who will be affected and how. It’s not just about writing code that works—it’s about making sure it works for people, and doesn’t cause harm through bias, unfair rewards, or a lack of transparency.
